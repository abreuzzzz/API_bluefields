import os
import json
import pandas as pd
import requests
from datetime import datetime, timedelta
from google.oauth2 import service_account
from googleapiclient.discovery import build
import time

# ===================== Autenticar com Google APIs =====================
json_secret = os.getenv("GDRIVE_SERVICE_ACCOUNT")
credentials_info = json.loads(json_secret)
scopes = ["https://www.googleapis.com/auth/drive", "https://www.googleapis.com/auth/spreadsheets"]
credentials = service_account.Credentials.from_service_account_info(credentials_info, scopes=scopes)
drive_service = build("drive", "v3", credentials=credentials)
sheets_service = build("sheets", "v4", credentials=credentials)

# ===================== Headers da API Conta Azul =====================
headers = {
    'X-Authorization': '00e3b816-f844-49ee-a75e-3da30f1c2630',
    'Content-Type': 'application/json',
    'User-Agent': 'Mozilla/5.0'
}

# ===================== Colunas a serem extra√≠das =====================
colunas_base = [
    "id",
    "description",
    "dueDate",
    "expectedPaymentDate",
    "lastAcquittanceDate",
    "unpaid",
    "paid",
    "status",
    "financialEvent.id",
    "financialEvent.competenceDate",
    "financialEvent.categoryDescriptions",
    "financialEvent.negotiator.id",
    "financialEvent.negotiator.name"
]

# ===================== Fun√ß√£o para gerar per√≠odos de 15 dias =====================
def gerar_periodos(data_inicio, data_fim):
    """Gera lista de per√≠odos de 15 dias entre data_inicio e data_fim"""
    periodos = []
    current_date = data_inicio
    
    while current_date <= data_fim:
        periodo_fim = min(current_date + timedelta(days=14), data_fim)
        periodos.append({
            'dueDateFrom': current_date.strftime('%Y-%m-%d'),
            'dueDateTo': periodo_fim.strftime('%Y-%m-%d')
        })
        current_date = periodo_fim + timedelta(days=1)
    
    return periodos

# ===================== Fun√ß√£o para fazer requisi√ß√£o com retry infinito =====================
def fazer_requisicao_com_retry(url, headers, payload, max_wait=300):
    """
    Faz requisi√ß√£o com retry infinito e backoff exponencial crescente.
    
    Args:
        url: URL da requisi√ß√£o
        headers: Headers HTTP
        payload: Corpo da requisi√ß√£o
        max_wait: Tempo m√°ximo de espera em segundos (padr√£o 300s = 5 min)
    
    Returns:
        response: Resposta da requisi√ß√£o bem-sucedida
    """
    tentativa = 0
    
    while True:  # Loop infinito at√© conseguir
        tentativa += 1
        
        try:
            response = requests.post(url, headers=headers, data=payload, timeout=30)
            
            # Se sucesso, retorna a resposta
            if response.status_code == 200:
                if tentativa > 1:
                    print(f"  ‚úÖ Requisi√ß√£o bem-sucedida ap√≥s {tentativa} tentativas!")
                return response
            
            # Se erro 429 (rate limit), aplica backoff
            elif response.status_code == 429:
                # Tenta pegar o Retry-After header
                retry_after = response.headers.get('Retry-After')
                
                if retry_after:
                    wait_time = min(int(retry_after), max_wait)
                    print(f"  ‚è≥ Rate limit (tentativa {tentativa}). Aguardando {wait_time}s (Retry-After)")
                else:
                    # Backoff exponencial: min(2^tentativa, max_wait)
                    wait_time = min((2 ** min(tentativa, 10)), max_wait)
                    print(f"  ‚è≥ Rate limit (tentativa {tentativa}). Aguardando {wait_time}s")
                
                time.sleep(wait_time)
                continue
            
            # Outros erros HTTP (500, 503, etc.)
            else:
                print(f"  ‚ö†Ô∏è Erro HTTP {response.status_code} (tentativa {tentativa})")
                wait_time = min((2 ** min(tentativa, 10)), max_wait)
                print(f"  ‚è≥ Aguardando {wait_time}s antes de tentar novamente...")
                time.sleep(wait_time)
                continue
                
        except requests.exceptions.Timeout:
            print(f"  ‚è±Ô∏è Timeout na requisi√ß√£o (tentativa {tentativa})")
            wait_time = min((2 ** min(tentativa, 10)), max_wait)
            print(f"  ‚è≥ Aguardando {wait_time}s antes de tentar novamente...")
            time.sleep(wait_time)
            continue
            
        except requests.exceptions.RequestException as e:
            print(f"  ‚ö†Ô∏è Erro na requisi√ß√£o (tentativa {tentativa}): {e}")
            wait_time = min((2 ** min(tentativa, 10)), max_wait)
            print(f"  ‚è≥ Aguardando {wait_time}s antes de tentar novamente...")
            time.sleep(wait_time)
            continue

# ===================== Fun√ß√£o para coletar dados de um per√≠odo =====================
def coletar_dados_periodo(periodo, max_pages=20, delay_entre_requisicoes=0.5):
    """Coleta dados paginados para um per√≠odo espec√≠fico com rate limiting"""
    page = 1
    page_size = 100
    items_periodo = []
    
    while page <= max_pages:
        url = f"https://services.contaazul.com/finance-pro-reader/v1/installment-view?page={page}&page_size={page_size}"
        payload = json.dumps({
            "dueDateFrom": periodo['dueDateFrom'],
            "dueDateTo": periodo['dueDateTo'],
            "quickFilter": "ALL",
            "search": "",
            "type": "REVENUE"
        })
        
        # Faz requisi√ß√£o com retry infinito - agora sempre vai conseguir
        response = fazer_requisicao_com_retry(url, headers, payload)
        data = response.json()
        items = data.get("items", [])
        
        if not items:
            break
        
        items_periodo.extend(items)
        page += 1
        
        print(f"  üìÑ P√°gina {page-1}: {len(items)} registros coletados ({periodo['dueDateFrom']} a {periodo['dueDateTo']})")
        
        # Delay entre requisi√ß√µes para evitar rate limit
        time.sleep(delay_entre_requisicoes)
    
    return items_periodo

# ===================== Coleta paginada da API por per√≠odos =====================
data_inicio = datetime(2015, 1, 1)
data_fim = datetime(2030, 12, 31)

print(f"üîÑ Gerando per√≠odos de 15 dias entre {data_inicio.date()} e {data_fim.date()}...")
periodos = gerar_periodos(data_inicio, data_fim)
print(f"üìä Total de per√≠odos a processar: {len(periodos)}")

all_items = []
total_periodos = len(periodos)

for idx, periodo in enumerate(periodos, 1):
    print(f"\nüîç Processando per√≠odo {idx}/{total_periodos}: {periodo['dueDateFrom']} a {periodo['dueDateTo']}")
    items_periodo = coletar_dados_periodo(periodo)
    all_items.extend(items_periodo)
    print(f"  ‚úÖ Total acumulado: {len(all_items)} registros")

print(f"\n‚úÖ Coleta finalizada! Total de registros: {len(all_items)}")

# ===================== Normaliza√ß√£o dos dados =====================
def extract_fields(item, campos):
    flat_item = {}
    for campo in campos:
        partes = campo.split('.')
        valor = item
        for parte in partes:
            valor = valor.get(parte, {}) if isinstance(valor, dict) else {}
        flat_item[campo] = valor if valor != {} else None
    return flat_item

dados_formatados = [extract_fields(item, colunas_base) for item in all_items]
df = pd.DataFrame(dados_formatados)

# Remover duplicatas baseadas no ID
df = df.drop_duplicates(subset=['id'], keep='first')
print(f"üìã Total de registros √∫nicos ap√≥s remo√ß√£o de duplicatas: {len(df)}")

# ===================== Buscar ID da planilha no Google Drive =====================
folder_id = "1_kJtBN_cr_WpND1nF3WtI5smi3LfIxNy"
sheet_name = "Financeiro_contas_a_receber_Bluefields"

query = f"name='{sheet_name}' and mimeType='application/vnd.google-apps.spreadsheet' and '{folder_id}' in parents and trashed=false"
results = drive_service.files().list(q=query, spaces='drive', fields="files(id, name)").execute()
files = results.get("files", [])

if not files:
    raise Exception(f"Planilha '{sheet_name}' n√£o encontrada na pasta do Drive.")

spreadsheet_id = files[0]['id']

# ===================== Limpar conte√∫do anterior da planilha =====================
print(f"\nüßπ Limpando planilha '{sheet_name}'...")
sheets_service.spreadsheets().values().clear(
    spreadsheetId=spreadsheet_id,
    range="A:Z"
).execute()

# ===================== Atualizar dados na planilha =====================
print(f"üì§ Atualizando planilha com {len(df)} registros...")
values = [df.columns.tolist()] + df.fillna("").values.tolist()
sheets_service.spreadsheets().values().update(
    spreadsheetId=spreadsheet_id,
    range="A1",
    valueInputOption="RAW",
    body={"values": values}
).execute()

print(f"\n‚úÖ Planilha Google '{sheet_name}' atualizada com sucesso!")
print(f"üìä Total de registros: {len(df)}")
